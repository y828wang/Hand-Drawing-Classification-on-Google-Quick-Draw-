{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\y884wang\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.utils.np_utils as kutils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras.callbacks as callbacks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = np.load('apple.npy')\n",
    "potato = np.load('potato.npy')\n",
    "basketball = np.load('basketball.npy')\n",
    "watermelon = np.load('watermelon.npy')\n",
    "circle = np.load('circle.npy')\n",
    "compass = np.load('compass.npy')\n",
    "donut = np.load('donut.npy')\n",
    "soccerball = np.load('soccer ball.npy')\n",
    "wheel = np.load('wheel.npy')\n",
    "cookie = np.load('cookie.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = np.c_[apple, np.zeros(apple.shape[0])]\n",
    "potato = np.c_[potato, np.ones(potato.shape[0])]\n",
    "basketball = np.c_[basketball, np.ones(basketball.shape[0])*2]\n",
    "watermelon = np.c_[watermelon, np.ones(watermelon.shape[0])*3]\n",
    "circle = np.c_[circle, np.ones(circle.shape[0])*4]\n",
    "compass = np.c_[compass, np.ones(compass.shape[0])*5]\n",
    "donut = np.c_[donut, np.ones(donut.shape[0])*6]\n",
    "soccerball = np.c_[soccerball, np.ones(soccerball.shape[0])*7]\n",
    "wheel = np.c_[wheel, np.ones(wheel.shape[0])*8]\n",
    "cookie = np.c_[cookie, np.ones(cookie.shape[0])*9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.concatenate((apple, potato,basketball,watermelon,circle,compass,donut,soccerball,wheel,cookie),axis=0)\n",
    "del apple, potato, basketball, watermelon, circle, compass, donut, soccerball, wheel, cookie\n",
    "X = Data[:,0:784]\n",
    "Y = Data[:,784]\n",
    "del Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = kutils.to_categorical(Y_train)\n",
    "y_test = kutils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122021, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1098183, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,Input,Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 50\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(784, input_dim=784, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(784, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(784, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1098183 samples, validate on 122021 samples\n",
      "Epoch 1/50\n",
      "1098183/1098183 [==============================] - 206s 188us/step - loss: 1.1045 - acc: 0.6281 - val_loss: 0.9312 - val_acc: 0.6819\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68195, saving model to weightsFNN\n",
      "Epoch 2/50\n",
      "1098183/1098183 [==============================] - 211s 192us/step - loss: 0.8660 - acc: 0.7054 - val_loss: 0.8201 - val_acc: 0.7259\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.68195 to 0.72587, saving model to weightsFNN\n",
      "Epoch 3/50\n",
      "1098183/1098183 [==============================] - 212s 193us/step - loss: 0.7629 - acc: 0.7405 - val_loss: 0.7312 - val_acc: 0.7485\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.72587 to 0.74854, saving model to weightsFNN\n",
      "Epoch 4/50\n",
      "1098183/1098183 [==============================] - 214s 195us/step - loss: 0.6999 - acc: 0.7614 - val_loss: 0.6871 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.74854 to 0.76405, saving model to weightsFNN\n",
      "Epoch 5/50\n",
      "1098183/1098183 [==============================] - 209s 190us/step - loss: 0.6589 - acc: 0.7744 - val_loss: 0.6537 - val_acc: 0.7767\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.76405 to 0.77665, saving model to weightsFNN\n",
      "Epoch 6/50\n",
      "1098183/1098183 [==============================] - 212s 193us/step - loss: 0.6295 - acc: 0.7835 - val_loss: 0.6334 - val_acc: 0.7814\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.77665 to 0.78137, saving model to weightsFNN\n",
      "Epoch 7/50\n",
      "1098183/1098183 [==============================] - 216s 197us/step - loss: 0.6062 - acc: 0.7912 - val_loss: 0.6261 - val_acc: 0.7848\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.78137 to 0.78480, saving model to weightsFNN\n",
      "Epoch 8/50\n",
      "1098183/1098183 [==============================] - 209s 190us/step - loss: 0.5869 - acc: 0.7975 - val_loss: 0.6117 - val_acc: 0.7881\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.78480 to 0.78811, saving model to weightsFNN\n",
      "Epoch 9/50\n",
      "1098183/1098183 [==============================] - 214s 195us/step - loss: 0.5705 - acc: 0.8028 - val_loss: 0.5993 - val_acc: 0.7936\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.78811 to 0.79356, saving model to weightsFNN\n",
      "Epoch 10/50\n",
      "1098183/1098183 [==============================] - 208s 190us/step - loss: 0.5559 - acc: 0.8075 - val_loss: 0.5840 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.79356 to 0.79835, saving model to weightsFNN\n",
      "Epoch 11/50\n",
      "1098183/1098183 [==============================] - 203s 185us/step - loss: 0.5429 - acc: 0.8120 - val_loss: 0.5842 - val_acc: 0.7983\n",
      "\n",
      "Epoch 00011: val_acc did not improve\n",
      "Epoch 12/50\n",
      "1098183/1098183 [==============================] - 210s 191us/step - loss: 0.5314 - acc: 0.8157 - val_loss: 0.5843 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00012: val_acc did not improve\n",
      "Epoch 13/50\n",
      "1098183/1098183 [==============================] - 202s 184us/step - loss: 0.5203 - acc: 0.8194 - val_loss: 0.5735 - val_acc: 0.7997\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.79835 to 0.79967, saving model to weightsFNN\n",
      "Epoch 14/50\n",
      "1098183/1098183 [==============================] - 203s 185us/step - loss: 0.5101 - acc: 0.8226 - val_loss: 0.5597 - val_acc: 0.8064\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.79967 to 0.80639, saving model to weightsFNN\n",
      "Epoch 15/50\n",
      "1098183/1098183 [==============================] - 202s 183us/step - loss: 0.5007 - acc: 0.8260 - val_loss: 0.5657 - val_acc: 0.8021\n",
      "\n",
      "Epoch 00015: val_acc did not improve\n",
      "Epoch 16/50\n",
      "1098183/1098183 [==============================] - 198s 180us/step - loss: 0.4915 - acc: 0.8294 - val_loss: 0.5659 - val_acc: 0.8031\n",
      "\n",
      "Epoch 00016: val_acc did not improve\n",
      "Epoch 17/50\n",
      "1098183/1098183 [==============================] - 202s 184us/step - loss: 0.4828 - acc: 0.8320 - val_loss: 0.5546 - val_acc: 0.8082\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.80639 to 0.80817, saving model to weightsFNN\n",
      "Epoch 18/50\n",
      "1098183/1098183 [==============================] - 201s 183us/step - loss: 0.4744 - acc: 0.8349 - val_loss: 0.5622 - val_acc: 0.8065\n",
      "\n",
      "Epoch 00018: val_acc did not improve\n",
      "Epoch 19/50\n",
      "1098183/1098183 [==============================] - 201s 183us/step - loss: 0.4665 - acc: 0.8376 - val_loss: 0.5415 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.80817 to 0.81148, saving model to weightsFNN\n",
      "Epoch 20/50\n",
      "1098183/1098183 [==============================] - 203s 185us/step - loss: 0.4589 - acc: 0.8403 - val_loss: 0.5498 - val_acc: 0.8086\n",
      "\n",
      "Epoch 00020: val_acc did not improve\n",
      "Epoch 21/50\n",
      "1098183/1098183 [==============================] - 209s 190us/step - loss: 0.4515 - acc: 0.8427 - val_loss: 0.5375 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.81148 to 0.81341, saving model to weightsFNN\n",
      "Epoch 22/50\n",
      "1098183/1098183 [==============================] - 206s 187us/step - loss: 0.4442 - acc: 0.8454 - val_loss: 0.5440 - val_acc: 0.8110\n",
      "\n",
      "Epoch 00022: val_acc did not improve\n",
      "Epoch 23/50\n",
      "1098183/1098183 [==============================] - 208s 189us/step - loss: 0.4378 - acc: 0.8477 - val_loss: 0.5385 - val_acc: 0.8141\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.81341 to 0.81415, saving model to weightsFNN\n",
      "Epoch 24/50\n",
      "1098183/1098183 [==============================] - 224s 204us/step - loss: 0.4312 - acc: 0.8500 - val_loss: 0.5325 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.81415 to 0.81599, saving model to weightsFNN\n",
      "Epoch 25/50\n",
      "1098183/1098183 [==============================] - 211s 192us/step - loss: 0.4248 - acc: 0.8522 - val_loss: 0.5433 - val_acc: 0.8127\n",
      "\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/50\n",
      "1098183/1098183 [==============================] - 212s 193us/step - loss: 0.4185 - acc: 0.8545 - val_loss: 0.5350 - val_acc: 0.8158\n",
      "\n",
      "Epoch 00026: val_acc did not improve\n",
      "Epoch 27/50\n",
      "1098183/1098183 [==============================] - 218s 198us/step - loss: 0.4122 - acc: 0.8568 - val_loss: 0.5564 - val_acc: 0.8062\n",
      "\n",
      "Epoch 00027: val_acc did not improve\n",
      "Epoch 28/50\n",
      "1098183/1098183 [==============================] - 212s 193us/step - loss: 0.4064 - acc: 0.8589 - val_loss: 0.5484 - val_acc: 0.8138\n",
      "\n",
      "Epoch 00028: val_acc did not improve\n",
      "Epoch 29/50\n",
      "1098183/1098183 [==============================] - 210s 192us/step - loss: 0.4006 - acc: 0.8608 - val_loss: 0.5395 - val_acc: 0.8152\n",
      "\n",
      "Epoch 00029: val_acc did not improve\n",
      "Epoch 30/50\n",
      "1098183/1098183 [==============================] - 206s 187us/step - loss: 0.3950 - acc: 0.8625 - val_loss: 0.5469 - val_acc: 0.8142\n",
      "\n",
      "Epoch 00030: val_acc did not improve\n",
      "Epoch 31/50\n",
      "1098183/1098183 [==============================] - 205s 187us/step - loss: 0.3891 - acc: 0.8646 - val_loss: 0.5931 - val_acc: 0.8016\n",
      "\n",
      "Epoch 00031: val_acc did not improve\n",
      "Epoch 32/50\n",
      "1098183/1098183 [==============================] - 207s 188us/step - loss: 0.3835 - acc: 0.8668 - val_loss: 0.5424 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.81599 to 0.81661, saving model to weightsFNN\n",
      "Epoch 33/50\n",
      "1098183/1098183 [==============================] - 206s 188us/step - loss: 0.3782 - acc: 0.8684 - val_loss: 0.5565 - val_acc: 0.8127\n",
      "\n",
      "Epoch 00033: val_acc did not improve\n",
      "Epoch 34/50\n",
      "1098183/1098183 [==============================] - 206s 188us/step - loss: 0.3726 - acc: 0.8704 - val_loss: 0.5467 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00034: val_acc did not improve\n",
      "Epoch 35/50\n",
      "1098183/1098183 [==============================] - 208s 189us/step - loss: 0.3674 - acc: 0.8722 - val_loss: 0.5546 - val_acc: 0.8131\n",
      "\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/50\n",
      "1098183/1098183 [==============================] - 207s 189us/step - loss: 0.3620 - acc: 0.8740 - val_loss: 0.5699 - val_acc: 0.8077\n",
      "\n",
      "Epoch 00036: val_acc did not improve\n",
      "Epoch 37/50\n",
      "1098183/1098183 [==============================] - 208s 190us/step - loss: 0.3565 - acc: 0.8762 - val_loss: 0.5540 - val_acc: 0.8158\n",
      "\n",
      "Epoch 00037: val_acc did not improve\n",
      "Epoch 38/50\n",
      "1098183/1098183 [==============================] - 209s 191us/step - loss: 0.3513 - acc: 0.8781 - val_loss: 0.5747 - val_acc: 0.8092\n",
      "\n",
      "Epoch 00038: val_acc did not improve\n",
      "Epoch 39/50\n",
      "1098183/1098183 [==============================] - 208s 189us/step - loss: 0.3462 - acc: 0.8796 - val_loss: 0.5581 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00039: val_acc did not improve\n",
      "Epoch 40/50\n",
      "1098183/1098183 [==============================] - 208s 189us/step - loss: 0.3410 - acc: 0.8815 - val_loss: 0.5617 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00040: val_acc did not improve\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098183/1098183 [==============================] - 209s 190us/step - loss: 0.3359 - acc: 0.8833 - val_loss: 0.5721 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00041: val_acc did not improve\n",
      "Epoch 42/50\n",
      "1098183/1098183 [==============================] - 207s 189us/step - loss: 0.3311 - acc: 0.8849 - val_loss: 0.5787 - val_acc: 0.8125\n",
      "\n",
      "Epoch 00042: val_acc did not improve\n",
      "Epoch 43/50\n",
      "1098183/1098183 [==============================] - 208s 190us/step - loss: 0.3258 - acc: 0.8867 - val_loss: 0.5726 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00043: val_acc did not improve\n",
      "Epoch 44/50\n",
      "1098183/1098183 [==============================] - 211s 192us/step - loss: 0.3209 - acc: 0.8884 - val_loss: 0.5808 - val_acc: 0.8139\n",
      "\n",
      "Epoch 00044: val_acc did not improve\n",
      "Epoch 45/50\n",
      "1098183/1098183 [==============================] - 209s 190us/step - loss: 0.3158 - acc: 0.8900 - val_loss: 0.5807 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00045: val_acc did not improve\n",
      "Epoch 46/50\n",
      "1098183/1098183 [==============================] - 208s 189us/step - loss: 0.3111 - acc: 0.8918 - val_loss: 0.5872 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00046: val_acc did not improve\n",
      "Epoch 47/50\n",
      "1098183/1098183 [==============================] - 209s 191us/step - loss: 0.3060 - acc: 0.8935 - val_loss: 0.5912 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00047: val_acc did not improve\n",
      "Epoch 48/50\n",
      "1098183/1098183 [==============================] - 205s 187us/step - loss: 0.3011 - acc: 0.8948 - val_loss: 0.6295 - val_acc: 0.8045\n",
      "\n",
      "Epoch 00048: val_acc did not improve\n",
      "Epoch 49/50\n",
      "1098183/1098183 [==============================] - 206s 188us/step - loss: 0.2965 - acc: 0.8968 - val_loss: 0.6392 - val_acc: 0.8055\n",
      "\n",
      "Epoch 00049: val_acc did not improve\n",
      "Epoch 50/50\n",
      "1098183/1098183 [==============================] - 206s 187us/step - loss: 0.2915 - acc: 0.8985 - val_loss: 0.6245 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00050: val_acc did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21290c89f98>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [ModelCheckpoint('weightsFNN',\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                            mode='auto')\n",
    "            ]\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"acc\"])\n",
    "model.fit(X_train, y_train, batch_size = batch_size, epochs=epochs,\n",
    "                   callbacks=callbacks,\n",
    "                   validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6256971310943138\n",
      "Test accuracy: 0.8089762039782252\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
